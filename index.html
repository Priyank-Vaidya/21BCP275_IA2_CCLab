<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Docker File Explanation</title>
</head>

<body>
    <h1>Docker File Explanation</h1>
    <p>The starting of the dockerfile specifies the author name and the dockerfile version</p>

    <code>FROM node:18.16.0 <br>
    FROM python:3.8-slim</code>

    <p>These are the image distributions along with their versions which will be used for executing our application inside the container.</p>

    <code>WORKDIR /backend</code>

    <p>With this command we are setting the working directory as the backend, which basically specifies the reference directory and files from /backend directory level in the container file system.</p>

    <code>RUN apt-get update && apt-get upgrade -y && \<br>
        npm</code>

    <p>Command used in Linux to update the system after package installation as done at the first step.</p>

    <h2>First stage of installation</h2>

    <code>COPY package*.json ./ <br>
        RUN npm install</code>

    <p>Firstly, this copies the server package.json dependency file. We aim to first download all the necessary dependencies and then copy the entire codebase to run the application in the container.</p>

    <code>COPY . .</code>

    <p>This copies all the files from the home directory to the container directory i.e /backend.</p>

    <h2>Second stage of installation and configuration</h2>

    <code>WORKDIR /backend/ml_model</code>

    <p>Setting the working directory in the container file system 1 layer below of /backend for ml_model.</p>

    <code>COPY ./ml_model/requirements.txt .</code>

    <p>First argument after COPY specifies the relative path of your local application and the one after it denotes the relative path with reference to the WORKDIR.</p>

    <p>Copying only the requirements first. This command will copy the contents of ml_model directory to the container /backend/ml_model directory.</p>

    <code>RUN pip install -r requirements.txt</code>

    <p>Installing all the requirements for running the Python application.</p>

    <code>COPY ./ml_model ./backend/ml_model</code>

    <p>Copying all the code in the ml_model local directory to the container directory.</p>

    <code>COPY ./configure-cloudsql-password.sh ../scripts</code>

    <p>In order to configure the password for Cloud SQL for storing the predictions of ml_model, I have written the bash file for performing and configuring the Google Cloud Cloud SQL.</p>

    <p>This copies the bash file into the /scripts directory at the /backend level.</p>

    <code>ENV GOOGLE_CLOUD_PROJECT ${GOOGLE_CLOUD_PROJECT} <br>
        ENV GOOGLE_CLOUD_SQL_USERNAME ${GOOGLE_CLOUD_SQL_USERNAME} <br>
        ENV GOOGLE_CLOUD_SQL_PASSWORD ${GOOGLE_CLOUD_SQL_PASSWORD} <br>
        ENV GOOGLE_CLOUD_SQL_DATABASE ${GOOGLE_CLOUD_SQL_DATABASE} <br>
        ENV GOOGLE_CLOUD_SQL_HOST ${GOOGLE_CLOUD_SQL_HOST} <br>
        ENV GOOGLE_CLOUD_SQL_PORT ${GOOGLE_CLOUD_SQL_PORT}</code>

    <p>As you see that environments specified after {$} needs to be configured by the automated workflow while initializing the VM on which the application needs to be run.</p>

    <p>Here VM is an abbreviation of Linux system on which the containers are executed.</p>

    <code>RUN python3 db.py</code>

    <p>Running the db.py file for using the Cloud SQL.</p>

    <code>EXPOSE 3000</code>

    <p>Exposing container port 3000 for open traffic to access the application.</p>

    <code>CMD ["python3", "stock_market_prediction.py"] <br>
        CMD ["npm", "start"]</code>

    <p>Finally, start executing the predictions by running the Python scripts.</p>

    <h1>Docker-compose.yml</h1>

    <p>There are 3 services for running interdependent containers.</p>
    <ul>
        <li>db</li>
        <li>app</li>
        <li>psql</li>
    </ul>

    <h3>db</h3>
    <p>It uses the Postgres public image from the Docker registry and runs the necessary configuration set up from configuration-postgres.sh bash file.</p>

    <p>There are some other parameters e.g. data path, volume, bridge.</p>

    <h3>app</h3>
    <p>Uses the Dockerfile as its dependency on executing application. It depends on db services, is connected to the same network as the db i.e. bridge.</p>

    <h3>psql</h3>
    <p>Depends on db service, connected to the same network for execution.</p>
</body>

</html>
